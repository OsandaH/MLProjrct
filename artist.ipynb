import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Load dataset
df = pd.read_csv('spotify_dataset.csv')

# Drop unnecessary columns
df = df.drop(columns=['uri', 'track'])

# Drop duplicate rows
df_unique = df.drop_duplicates()

# ==============================
# Artist Popularity Analysis
# ==============================

# 1. Compute average popularity per artist
artist_popularity = df_unique.groupby('artist')['popularity'].mean().sort_values(ascending=False).reset_index()

# 2. Plot top 20 artists by average popularity
plt.figure(figsize=(12, 6))
sns.barplot(x='popularity', y='artist', data=artist_popularity.head(20), palette='viridis')
plt.title('Top 20 Artists by Average Song Popularity')
plt.xlabel('Average Popularity')
plt.ylabel('Artist')
plt.tight_layout()
plt.show()

# 3. OPTIONAL: Merge artist average popularity back into the dataframe (useful as a feature)
df_unique = df_unique.merge(artist_popularity.rename(columns={'popularity': 'artist_avg_popularity'}), 
                            on='artist', 
                            how='left')

# ==============================
# Categorical Encoding
# ==============================

# Categorical features to encode
categorical_columns = ['key', 'time_signature', 'mode', 'decade']

# One-Hot Encoding for categorical variables
encoder = OneHotEncoder(sparse_output=False, drop='first')  # Avoid dummy variable trap

encoded_cats = encoder.fit_transform(df_unique[categorical_columns])

df_encoded = pd.DataFrame(encoded_cats, 
                          columns=encoder.get_feature_names_out(categorical_columns),
                          index=df_unique.index)

# ==============================
# Numerical Scaling
# ==============================

# Select numerical columns (excluding categorical ones)
numerical_columns = df_unique.select_dtypes(include=['number']).columns.difference(categorical_columns)

# Standardize numerical features
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df_unique[numerical_columns]), 
                         columns=numerical_columns, 
                         index=df_unique.index)

# ==============================
# Combine processed features
# ==============================

df_processed = pd.concat([df_scaled, df_encoded], axis=1)

# ==============================
# Ready for ML (Train/Test Split)
# ==============================

X = df_processed.drop(columns=['popularity'])  # Features
y = df_processed['popularity']                # Target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Processed dataset ready for model training!")
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
